<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd"> <html><body> <h2 id="teoría">Teoría</h2> <p>Learning Vector Quantization (LVQ) es un algoritmo de clasificación supervisada basado en prototipos, que busca representar cada clase mediante vectores representativos (‘prototipos’) que se ajustan iterativamente a los datos.</p> <p align="center"> <img src="/assets/img/lvq_iman.gif" alt="LVQ Gif" width="500"> </p> <p>Los prototipos son como imanes: se acercan a los datos de su propia clase y se alejan de los de clases diferentes.</p> <p>El procedimiento de aprendizaje del LVQ puede resumirse de la siguiente manera:</p> <p align="center"> <img src="/assets/img/lvq_process.png" alt="LVQ Process" width="500"> </p> <p>Podemos pensar en los prototipos como algo similar a los centroides que se presentan en KMeans. Sin embargo, el ajuste iterativo es diferente. A diferencia de KMeans, que es un algoritmo no supervisado, LVQ es supervisado, ya que el ajuste de los prototipos depende no solo de la distancia, sino también de la clase de cada ejemplo.</p> <p>Viendo el procesamiento a detalle tenemos lo siguiente:</p> <p align="center"> <img src="/assets/img/lvq_process_detailed.pngg" alt="LVQ Detailed" width="500"> </p> <p>Añadiendo información a los procesos de LVQ tenemos:</p> <ul> <li>Inicialización de prototipos: Importante mencionar que el numero de prototipos es respecto al número de clases. La inicialización de protitpos puede realizarse con valores aleatorios, o tambien copiando un valor aleatorio de los registros presentes en el dataset.</li> <li>Ajuste iterativo basado en datos de entrenamiento: En este proceso se evidencia la clara diferencia con respecto a KMeans. Primero se debe calcular la distancia de un registro i con respecto a cada prototipo. Esta distancia puede ser euclidiana, manhattan, etc. Posteriormente nos enfocamos en el prototipo más cercano a dicho registro i. Si el prototipo más cercano es de la misma clase que el registro i se actualiza el valor del prototipo (w) con la siguiente formula:</li> </ul> \[w(t+1) = w(t) + \alpha \cdot \bigl( x - w(t) \bigr)\] <p>En otras palabras acercamos al prototipo al registro i, porque son la misma clase. Por otro lado, si el prototipo mas cercano es de una clase diferente al registro i se actualiza el prototipo (w) para alejar al prototipo:</p> \[w(t+1) = w(t) - \alpha \cdot \bigl( x - w(t) \bigr)\] <ul> <li>Clasificación por el prototipo: En la fase de clasificación, un nuevo registro es asignado a la clase de su prototipo más cercano, funcionando de manera similar a un clasificador k-NN, pero utilizando solo los prototipos como referencia.</li> </ul> <hr> <h2 id="código">Código</h2> <p>La implementación de LVQ se puede realizar de la siguiente manera:</p> <p>1) Generamos un dataset sintético:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">class1</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span> 
<span class="n">class2</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randn</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">]</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">class1</span><span class="p">,</span> <span class="n">class2</span><span class="p">))</span>
<span class="n">labels</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span> <span class="o">+</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span></code></pre></figure> <p>2) Definimos el modelo:</p> <p>Inicializamos los parámetros necesarios para el funcionamiento de LVQ:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">n_classes</span> <span class="o">=</span> <span class="mi">2</span>  
<span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span> 
<span class="n">n_iterations</span> <span class="o">=</span> <span class="mi">100</span>  </code></pre></figure> <p>En este caso inicializamos los prototipos basandonos en una elección randómica en nuestro dataset:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">prototypes</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="n">data</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">][</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">choice</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="n">labels</span> <span class="o">==</span> <span class="n">i</span><span class="p">]))]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_classes</span><span class="p">)])</span></code></pre></figure> <p>Definimos la distancia para el ajuste de los prototipos, en este caso la distancia euclideana:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">((</span><span class="n">a</span> <span class="o">-</span> <span class="n">b</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">))</span></code></pre></figure> <p>Ahora definimos LVQ con numpy:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n_iterations</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">data</span><span class="p">)):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> 
        <span class="n">y</span> <span class="o">=</span> <span class="n">labels</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
        
        <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prototype</span><span class="p">)</span> <span class="k">for</span> <span class="n">prototype</span> <span class="ow">in</span> <span class="n">prototypes</span><span class="p">])</span>
        <span class="n">closest_prototype_idx</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">closest_prototype_idx</span> <span class="o">==</span> <span class="n">y</span><span class="p">:</span> 
            <span class="n">prototypes</span><span class="p">[</span><span class="n">closest_prototype_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">prototypes</span><span class="p">[</span><span class="n">closest_prototype_idx</span><span class="p">]</span> <span class="o">+</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">prototypes</span><span class="p">[</span><span class="n">closest_prototype_idx</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="n">prototypes</span><span class="p">[</span><span class="n">closest_prototype_idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">prototypes</span><span class="p">[</span><span class="n">closest_prototype_idx</span><span class="p">]</span> <span class="o">-</span> <span class="n">learning_rate</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">prototypes</span><span class="p">[</span><span class="n">closest_prototype_idx</span><span class="p">])</span></code></pre></figure> <p>3) Definimos la función de clasificación:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prototypes</span><span class="p">):</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prototype</span><span class="p">)</span> <span class="k">for</span> <span class="n">prototype</span> <span class="ow">in</span> <span class="n">prototypes</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span></code></pre></figure> <p>4) [EXTRA] Para evaluar LVQ realizaremos lo siguiente:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">def</span> <span class="nf">classify</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prototypes</span><span class="p">):</span>
    <span class="n">distances</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">array</span><span class="p">([</span><span class="nf">euclidean_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prototype</span><span class="p">)</span> <span class="k">for</span> <span class="n">prototype</span> <span class="ow">in</span> <span class="n">prototypes</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">argmin</span><span class="p">(</span><span class="n">distances</span><span class="p">)</span></code></pre></figure> <p>5) [EXTRA] La visualización del rendimiento de LVQ se realiza a través de:</p> <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">class1</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">class1</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Clase 1</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">class2</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">class2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Clase 2</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">scatter</span><span class="p">(</span><span class="n">prototypes</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">prototypes</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">green</span><span class="sh">'</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Prototipos</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">"</span><span class="s">Datos y prototipos de LVQ</span><span class="sh">"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">show</span><span class="p">()</span></code></pre></figure> <p>Citations are then used in the article body with the <code class="language-plaintext highlighter-rouge">&lt;d-cite&gt;</code> tag. The key attribute is a reference to the id provided in the bibliography. The key attribute can take multiple ids, separated by commas.</p> <p>The citation is presented inline like this: <d-cite key="gregor2015draw"></d-cite> (a number that displays more information on hover). If you have an appendix, a bibliography is automatically created and populated in it.</p> <p>Distill chose a numerical inline citation style to improve readability of citation dense articles and because many of the benefits of longer citations are obviated by displaying more information on hover. However, we consider it good style to mention author last names if you discuss something at length and it fits into the flow well — the authors are human and it’s nice for them to have the community associate them with their work.</p> <hr> <h2 id="footnotes">Footnotes</h2> <p>Just wrap the text you would like to show up in a footnote in a <code class="language-plaintext highlighter-rouge">&lt;d-footnote&gt;</code> tag. The number of the footnote will be automatically generated.<d-footnote>This will become a hoverable footnote.</d-footnote></p> <hr> <p>This line is separated from the one above by two newlines, so it will be a <em>separate paragraph</em>.</p> <p>This line is also a separate paragraph, but… This line is only separated by a single newline, so it’s a separate line in the <em>same paragraph</em>.</p> </body></html>